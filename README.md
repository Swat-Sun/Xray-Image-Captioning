# Xray-Image-Captioning
This research effort aims to generate reports of chest X-Rays initially using pre-trained models to perform description extraction and then using that info to generate caption using LSTMs and GRUs. The dataset being used is publicly available from Indiana University and consists of chest X-ray images and reports. The goal is to predict the physician's notes of the information associated with the image.

# Data Extraction, Cleaning & EDA

# Experiment 1
Bahdanau attention based encoder and decoder model & glove embedding.

# Experiment 2
Luong attention based encoder decoder model & glove embedding.

# Experiment 3
Inception v3 pretrained ImageNet model & glove embedding.

# Experiment 3
Attention based encoder and decoder model & Spacy Embedding
